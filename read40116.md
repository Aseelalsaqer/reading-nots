# Machine learning:

is the practice of teaching computers how to learn patterns from data, often for making decisions or predictions.

- Bird's Eye View:
  This data science primer will cover exploratory analysis, data cleaning, feature engineering, algorithm selection, and model training
- Model - a set of patterns learned from data.
- Algorithm - a specific ML process used to train a model.
- Training data - the dataset from which the algorithm learns the model.
- Test data - a new dataset for reliably evaluating model performance.
- Features - Variables (columns) in the dataset used to train the model.
- Target variable - A specific variable you're trying to predict.
- Observations - Data points (rows) in the dataset.
- There are 5 core steps:
  1)Exploratory Analysis:

First, "get to know" the data. This step should be quick, efficient, and decisive.

2)Data Cleaning:

Then, clean your data to avoid many common pitfalls. Better data beats fancier algorithms.

3)Feature Engineering:

Next, help your algorithms "focus" on what's important by creating new features.

4)Algorithm Selection:

Choose the best, most appropriate algorithms without wasting your time.

5)Model Training:

Finally, train your models. This step is pretty formulaic once you've done the first 4.

- Key takeaway: Machine learning should not be haphazard and piecemeal. It should be systematic and organized.

## exploratory analysis

The purpose of exploratory analysis is to "get to know" the dataset. Doing so upfront will make the rest of the project much smoother, in 3 main ways:

- You’ll gain valuable hints for Data Cleaning (which can make or break your models).
- You’ll think of ideas for Feature Engineering (which can take your models from good to great).
- You’ll get a "feel" for the dataset, which will help you communicate results and deliver greater impact.

1.  Plot Numerical Distributions
2.  Plot Categorical Distributions
3.  Plot Segmentations

## Data Cleaning

- The first step to data cleaning is **removing unwanted observations** from your dataset.

- This includes duplicate or irrelevant observations.
  **Duplicate observations**
  Duplicate observations most frequently arise during data collection, such as when you:

  1)Combine datasets from multiple places
  2)Scrape data

3. Receive data from clients/other departments

**Irrelevant observations**
Irrelevant observations are those that don’t actually fit the specific problem that you’re trying to solve.

For example, if you were building a model for Single-Family homes only, you wouldn't want observations for Apartments in there.
This is also a great time to review your charts from Exploratory Analysis. You can look at the distribution charts for categorical features to see if there are any classes that shouldn’t be there.
Checking for irrelevant observations before engineering features can save you many headaches down the road.
**Fix Structural Errors**
**Filter Unwanted Outliers**
**Handle Missing Data**

## Feature Engineering

Feature engineering is about creating new input features from your existing ones.

## Model Training
